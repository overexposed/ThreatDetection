{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object') or True):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocessing(df):\n",
    "    # df[\"label\"][df[\"label\"]==\"benign\"] = 0\n",
    "    # df[\"label\"][df[\"label\"]==\"outlier\"] = 1\n",
    "    # df[\"label\"][df[\"label\"]==\"malicious\"] = 2\n",
    "    # df[\"label\"] = df[\"label\"].astype(np.int16)\n",
    "\n",
    "    df[\"dest_port\"] = df[\"dest_port\"] / df[\"dest_port\"].max()\n",
    "    df[\"src_port\"] = df[\"src_port\"] / df[\"src_port\"].max()\n",
    "    df[\"dest_port\"][df[\"dest_port\"].isna()] = -1\n",
    "    df[\"src_port\"][df[\"src_port\"].isna()] = -1\n",
    "\n",
    "\n",
    "class ThreatDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.features = self.df.drop(columns = ['label']).values\n",
    "        df_enc = oneHotEncode(self.df, [\"label\"])\n",
    "        self.label = df_enc[[\"label_benign\", \"label_malicious\", \"label_outlier\"]].to_numpy()\n",
    "        # self.label = self.df.label.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.df))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.features[idx], dtype=torch.float), torch.tensor(self.label[idx], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_ipt</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>dest_ip</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_pkts_out</th>\n",
       "      <th>num_pkts_in</th>\n",
       "      <th>proto</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>time_end</th>\n",
       "      <th>time_start</th>\n",
       "      <th>total_entropy</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>342</td>\n",
       "      <td>3679</td>\n",
       "      <td>786</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>5.436687</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>57392.0</td>\n",
       "      <td>1592533725648144</td>\n",
       "      <td>1592533725632946</td>\n",
       "      <td>21860.918000</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.015198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>55972.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>49453</td>\n",
       "      <td>49493.0</td>\n",
       "      <td>1592533744644904</td>\n",
       "      <td>1592533744644904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>outlier</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>15440</td>\n",
       "      <td>942</td>\n",
       "      <td>786</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>2.203135</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>60512.0</td>\n",
       "      <td>1592533770936279</td>\n",
       "      <td>1592533770933553</td>\n",
       "      <td>36091.754000</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.002726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.217391</td>\n",
       "      <td>622</td>\n",
       "      <td>31010</td>\n",
       "      <td>786</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>1.189945</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>60490.0</td>\n",
       "      <td>159253376770238</td>\n",
       "      <td>15925337672353</td>\n",
       "      <td>37640.355000</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.467080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>59498.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>1592533772973114</td>\n",
       "      <td>1592533772973087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765355</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>270</td>\n",
       "      <td>191</td>\n",
       "      <td>786</td>\n",
       "      <td>445.0</td>\n",
       "      <td>4.570315</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>38592</td>\n",
       "      <td>50822.0</td>\n",
       "      <td>1592611182688869</td>\n",
       "      <td>1592611181766454</td>\n",
       "      <td>2106.915300</td>\n",
       "      <td>outlier</td>\n",
       "      <td>0.922415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765356</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>340</td>\n",
       "      <td>611</td>\n",
       "      <td>786</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>6.196277</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>51148.0</td>\n",
       "      <td>159261118308182</td>\n",
       "      <td>1592611183069313</td>\n",
       "      <td>5892.659700</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.012507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765357</th>\n",
       "      <td>1.111111</td>\n",
       "      <td>348</td>\n",
       "      <td>9126</td>\n",
       "      <td>786</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>2.999871</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>51146.0</td>\n",
       "      <td>1592611183081913</td>\n",
       "      <td>1592611183070674</td>\n",
       "      <td>28420.775000</td>\n",
       "      <td>benign</td>\n",
       "      <td>0.011239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765358</th>\n",
       "      <td>1602.500000</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.060336</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1592611179165795</td>\n",
       "      <td>159261117275518</td>\n",
       "      <td>237.515150</td>\n",
       "      <td>malicious</td>\n",
       "      <td>6.410615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765359</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.020244</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1592611180116055</td>\n",
       "      <td>1592611180115974</td>\n",
       "      <td>114.267365</td>\n",
       "      <td>malicious</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765360 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_ipt  bytes_in  bytes_out  dest_ip  dest_port   entropy  \\\n",
       "0          7.500000       342       3679      786     9200.0  5.436687   \n",
       "1          0.000000         0          0      786    55972.0  0.000000   \n",
       "2          0.500000     15440        942      786     9300.0  2.203135   \n",
       "3         20.217391       622      31010      786     9300.0  1.189945   \n",
       "4          0.000000         0          0      786    59498.0  0.000000   \n",
       "...             ...       ...        ...      ...        ...       ...   \n",
       "765355   118.000000       270        191      786      445.0  4.570315   \n",
       "765356     6.000000       340        611      786     9200.0  6.196277   \n",
       "765357     1.111111       348       9126      786     9200.0  2.999871   \n",
       "765358  1602.500000       112        112      786        NaN  1.060336   \n",
       "765359     0.000000        56         56      786        NaN  1.020244   \n",
       "\n",
       "        num_pkts_out  num_pkts_in  proto  src_ip  src_port          time_end  \\\n",
       "0                  2            2      6     786   57392.0  1592533725648144   \n",
       "1                  1            1      6   49453   49493.0  1592533744644904   \n",
       "2                  3            3      6     786   60512.0  1592533770936279   \n",
       "3                 23            5      6     786   60490.0   159253376770238   \n",
       "4                  1            1      6     786    9300.0  1592533772973114   \n",
       "...              ...          ...    ...     ...       ...               ...   \n",
       "765355             6            6      6   38592   50822.0  1592611182688869   \n",
       "765356             2            2      6     786   51148.0   159261118308182   \n",
       "765357             9            3      6     786   51146.0  1592611183081913   \n",
       "765358             2            2      1   16509       NaN  1592611179165795   \n",
       "765359             1            1      1   16509       NaN  1592611180116055   \n",
       "\n",
       "              time_start  total_entropy      label  duration  \n",
       "0       1592533725632946   21860.918000     benign  0.015198  \n",
       "1       1592533744644904       0.000000    outlier  0.000000  \n",
       "2       1592533770933553   36091.754000     benign  0.002726  \n",
       "3         15925337672353   37640.355000     benign  0.467080  \n",
       "4       1592533772973087       0.000000     benign  0.000027  \n",
       "...                  ...            ...        ...       ...  \n",
       "765355  1592611181766454    2106.915300    outlier  0.922415  \n",
       "765356  1592611183069313    5892.659700     benign  0.012507  \n",
       "765357  1592611183070674   28420.775000     benign  0.011239  \n",
       "765358   159261117275518     237.515150  malicious  6.410615  \n",
       "765359  1592611180115974     114.267365  malicious  0.000081  \n",
       "\n",
       "[765360 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Dataset/2020/06/2020.06.19/2020.06.19.csv\"\n",
    "df = pd.read_csv(path)\n",
    "preprocessing(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=\"label\"), df[\"label\"], test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier( random_state=2)   # 5min 48\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9836895926971185\n",
      "f1_score:  [0.99933627 0.97690361 0.94961798]\n"
     ]
    }
   ],
   "source": [
    "y_pred_gbc = gbc.predict(X_test)\n",
    "print(\"accuracy_score: \", accuracy_score(y_pred_gbc, y_test))\n",
    "print(\"f1_score: \", f1_score(y_pred_gbc, y_test, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.9838433254634245\n"
     ]
    }
   ],
   "source": [
    "print(\"f1_score: \", f1_score(y_pred_gbc, y_test, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=2, verbose=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=2)     # 1min 11\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9984625971220515\n",
      "f1_score:  [0.99981863 0.99788254 0.99556769]\n",
      "f1_score:  0.998463765873796\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"accuracy_score: \", accuracy_score(y_pred_rf, y_test))\n",
    "print(\"f1_score: \", f1_score(y_pred_rf, y_test, average=None))\n",
    "print(\"f1_score: \", f1_score(y_pred_rf, y_test, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  {1: 0.9518514217611043}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881, 9: 0.9802876335898271}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881, 9: 0.9802876335898271, 10: 0.9814151655877491}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881, 9: 0.9802876335898271, 10: 0.9814151655877491, 11: 0.9807568873519527}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881, 9: 0.9802876335898271, 10: 0.9814151655877491, 11: 0.9807568873519527, 12: 0.9782976520369402}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881, 9: 0.9802876335898271, 10: 0.9814151655877491, 11: 0.9807568873519527, 12: 0.9782976520369402, 13: 0.9783289500591218}\n",
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881, 9: 0.9802876335898271, 10: 0.9814151655877491, 11: 0.9807568873519527, 12: 0.9782976520369402, 13: 0.9783289500591218, 14: 0.9804196577579725}\n"
     ]
    }
   ],
   "source": [
    "kbest_scores = {}\n",
    "for i in range(1, X_train.columns.size):\n",
    "    selector = SelectKBest(mutual_info_classif, k=i)\n",
    "    selector.fit(X_train, y_train)\n",
    "\n",
    "    X_train_5Best = selector.transform(X_train)\n",
    "    X_test_5Best = selector.transform(X_test)\n",
    "\n",
    "    gbc.fit(X_train_5Best, y_train)         # 5min 22\n",
    "    y_pred_5best = gbc.predict(X_test_5Best)\n",
    "\n",
    "\n",
    "    kbest_scores[i] = f1_score(y_test, y_pred_5best, average=\"weighted\")\n",
    "\n",
    "print(\"f1_score: \", kbest_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  {1: 0.9518514217611043, 2: 0.9757506152589774, 3: 0.9802506621905414, 4: 0.9805085918129378, 5: 0.9807785779536278, 6: 0.9822851547744932, 7: 0.9808383219500043, 8: 0.9765559609201881, 9: 0.9802876335898271, 10: 0.9814151655877491, 11: 0.9807568873519527, 12: 0.9782976520369402, 13: 0.9783289500591218, 14: 0.9804196577579725}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"f1_score: \", kbest_scores)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure()\n",
    "plt.bar(kbest_scores.keys(), kbest_scores.values(), width=0.5)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
